{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YhDx0Tsyyhd"
      },
      "source": [
        "# RNN Based molucule generation\n",
        "\n",
        "Laurent Cetinsoy\n",
        "\n",
        "In this hands-on we want to generate molecule formulas for denovo-drug discovery.\n",
        "\n",
        "For that we need to use Generative models. Generative models are models which goes beyond classification or simple regression : they are able to generate data that look like previously seens dataset.\n",
        "\n",
        "There exists a lot of models :\n",
        "\n",
        "- Bayesian models like graphical models\n",
        "- Recurrent models (for sequence generation like texte)\n",
        "- Variational auto encoders\n",
        "- Generative adversarial models\n",
        "- Flow and diffusion models\n",
        "\n",
        "\n",
        "In the hands-on we will start by  trainning a character based RNN to generate smile molecules\n",
        "\n",
        "\n",
        "We want to feed smile representations of molecules to an RNN.\n",
        "The basic idea is we will train it to predict the next smile token of a molecule given the previous one.\n",
        "\n",
        "For instance for the following molecule \"CC(=O)NC1=CC=C(O)C=C1\" will may give to the model\n",
        "\n",
        "X = \"CC(=O)N\"\n",
        "y = C\n",
        "\n",
        "and ask the RNN to learn to predict y given X\n",
        "\n",
        "Like a standard language model !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Que9IFyyhk"
      },
      "source": [
        "## RNN Language model\n",
        "\n",
        "\n",
        "A language model is a model which predict the next token of a sequence given the previous ones :\n",
        "\n",
        "$ P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "This model can be learned with a Recurrent neural network\n",
        "\n",
        "$ y = P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p}) = RNN_{\\theta} (X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n",
        "\n",
        "\n",
        "In order to train such model you need a corpus of data.\n",
        "\n",
        "\n",
        "\n",
        "There are two main ways to do that : Word level model or character level model\n",
        "\n",
        "For character level models, an interesting resource is : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaSGBHWXyyhm"
      },
      "source": [
        "Explain briefly what is the difference between word based language model and character based language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3FB6X4yyhn"
      },
      "source": [
        "Les modèles basés sur des caractères fonctionnent sur la prédiction de la lettre la plus probable de suivre une séquence. Les modèles basés sur des mots fonctionnent en revanche sur la prédiction du mot le plus probable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU_SbWlJyyhn"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CAnQcj3yyho"
      },
      "source": [
        "Dowload the following dataset : https://github.com/joeymach/Leveraging-VAE-to-generate-molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n4Vt5n4o8jc",
        "outputId": "a7b05970-ab63-4a8a-9faa-c8d50ee54d5d"
      },
      "outputs": [],
      "source": [
        "! [ -e 250k_smiles.csv ] || wget https://raw.githubusercontent.com/joeymach/Leveraging-VAE-to-generate-molecules/master/250k_smiles.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyvW9PMyyyhr"
      },
      "source": [
        "Import pandas and load the first 1000 lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p2FuRl15yyhr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jdBAbT-Apc4g"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(filepath_or_buffer=\"250k_smiles.csv\", nrows=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO3XWPQMyyhs"
      },
      "source": [
        "Display the first rows of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zjQ6_NK3yyht",
        "outputId": "fb967260-a44c-48ce-de64-1886c2c71665"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>logP</th>\n",
              "      <th>qed</th>\n",
              "      <th>SAS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n</td>\n",
              "      <td>5.05060</td>\n",
              "      <td>0.702012</td>\n",
              "      <td>2.084095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n</td>\n",
              "      <td>3.11370</td>\n",
              "      <td>0.928975</td>\n",
              "      <td>3.432004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...</td>\n",
              "      <td>4.96778</td>\n",
              "      <td>0.599682</td>\n",
              "      <td>2.470633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...</td>\n",
              "      <td>4.00022</td>\n",
              "      <td>0.690944</td>\n",
              "      <td>2.822753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...</td>\n",
              "      <td>3.60956</td>\n",
              "      <td>0.789027</td>\n",
              "      <td>4.035182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              smiles     logP       qed  \\\n",
              "0          CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n  5.05060  0.702012   \n",
              "1     C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n  3.11370  0.928975   \n",
              "2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  4.96778  0.599682   \n",
              "3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  4.00022  0.690944   \n",
              "4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  3.60956  0.789027   \n",
              "\n",
              "        SAS  \n",
              "0  2.084095  \n",
              "1  3.432004  \n",
              "2  2.470633  \n",
              "3  2.822753  \n",
              "4  4.035182  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfyMV4QXyyhu"
      },
      "source": [
        "## Processing the data\n",
        "\n",
        "We need to do the following things :\n",
        "\n",
        "- convert smile tokens to numbers\n",
        "- build  smile token sequences and corresponding labels pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-wwZXCOyyhu"
      },
      "source": [
        "Compute the biggest smile molecule size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjihMHOYuYz0",
        "outputId": "778e12b6-4606-4140-8c1d-dc1f51a01e44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(max(df[\"smiles\"], key=lambda s: len(s)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocxq6YQmuvMw"
      },
      "source": [
        "Code a function unic_characters(string) which return the unic characters in a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PuGJsUIVA3il"
      },
      "outputs": [],
      "source": [
        "def unic_characters(string):\n",
        "    return np.unique(list(string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfQN1kx-8qz5",
        "outputId": "0bbc3566-c781-4c8c-ea1e-3b327df16043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['A', 'B', 'C', 'D', 'E'], dtype='<U1')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unic_characters(\"AAAABAAACCCDDDEE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DITuFSeyyhx"
      },
      "source": [
        "Concatenate all smile string of the pandas dataframe and use **unic_characters** to get the unic_characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pweel8bxyyhx"
      },
      "outputs": [],
      "source": [
        "unic_chars = unic_characters(df[\"smiles\"].sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXmrYw-nyyhy"
      },
      "source": [
        "Code a function **map_char_to_int(unic_chars)** which returns a dictionnary where each char is assigned an int value.\n",
        "Add a character to specify the end of the molecule (like \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dPvQzt1Oyyhy"
      },
      "outputs": [],
      "source": [
        "def map_char_to_int(unic_chars):\n",
        "    dictionnary = {}\n",
        "    for i, char in enumerate(unic_chars):\n",
        "        dictionnary[char] = i\n",
        "    return dictionnary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJAKz2_KCN12",
        "outputId": "4fee2695-3923-4df0-9b57-6d1a60524ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " '#': 1,\n",
              " '(': 2,\n",
              " ')': 3,\n",
              " '+': 4,\n",
              " '-': 5,\n",
              " '/': 6,\n",
              " '1': 7,\n",
              " '2': 8,\n",
              " '3': 9,\n",
              " '4': 10,\n",
              " '5': 11,\n",
              " '6': 12,\n",
              " '7': 13,\n",
              " '=': 14,\n",
              " '@': 15,\n",
              " 'B': 16,\n",
              " 'C': 17,\n",
              " 'F': 18,\n",
              " 'H': 19,\n",
              " 'I': 20,\n",
              " 'N': 21,\n",
              " 'O': 22,\n",
              " 'S': 23,\n",
              " '[': 24,\n",
              " '\\\\': 25,\n",
              " ']': 26,\n",
              " 'c': 27,\n",
              " 'l': 28,\n",
              " 'n': 29,\n",
              " 'o': 30,\n",
              " 'r': 31,\n",
              " 's': 32}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "map_char_to_int(unic_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrgQmRgyyhz"
      },
      "source": [
        "Code a function map_int_to_char(unic_chars) which returns the reverse mapping.\n",
        "\n",
        "If you want you can merge both functions in a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mX3883sYyyh0"
      },
      "outputs": [],
      "source": [
        "def map_int_to_char(unic_chars):\n",
        "    dictionnary = {}\n",
        "    for i, char in enumerate(unic_chars):\n",
        "        dictionnary[i] = char\n",
        "    return dictionnary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MolEncoder:\n",
        "    def __init__(self, unic_characters: np.array):\n",
        "        self.unic_chars = unic_characters\n",
        "        self.char_to_int = map_char_to_int(unic_chars)\n",
        "        self.int_to_char = map_int_to_char(unic_chars)\n",
        "        self.voc_len = len(unic_chars)\n",
        "\n",
        "    def get_char(self, int_val):\n",
        "        return self.int_to_char[int_val]\n",
        "\n",
        "    def get_int(self, char):\n",
        "        return self.char_to_int[char]\n",
        "\n",
        "    def encode_mol(self, smiles):\n",
        "        return np.array([self.char_to_int[char] for char in smiles])\n",
        "\n",
        "    def get_one_hot(self, int_value: int = None, char: chr = None):\n",
        "        if int_value is None:\n",
        "            int_value = self.get_int(char)\n",
        "        elif char is None:\n",
        "            char = self.get_char(int_value)\n",
        "        one_hot = np.zeros(self.voc_len)\n",
        "        one_hot[int_value] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def decode_mol(self, encoded_mol):\n",
        "        return \"\".join([self.int_to_char[int] for int in encoded_mol])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PyYopQ3F_H9",
        "outputId": "f9ba15f7-4c3b-4c9c-b781-ffd1bec8a670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C\n",
            "17\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "mol_encoder = MolEncoder(unic_chars)\n",
        "print(mol_encoder.get_char(17))\n",
        "print(mol_encoder.get_int(\"C\"))\n",
        "print(mol_encoder.get_one_hot(17))\n",
        "assert np.all(mol_encoder.get_one_hot(17) == mol_encoder.get_one_hot(char=\"C\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "mol_smile = df[\"smiles\"][random.randint(0, len(df))]\n",
        "ecnoded = mol_encoder.encode_mol(mol_smile)\n",
        "assert mol_encoder.decode_mol(ecnoded) == mol_smile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1etZs7T3yyh1"
      },
      "source": [
        "For each smile molecule add the ending token to it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKC4TyuZyyh1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpuIn5z1yyh2"
      },
      "source": [
        "## Building the dataset\n",
        "\n",
        "Now we will create the dataset so that it has the good share for our Keras LSTM model\n",
        "\n",
        "Remember Keras recurrent models expect a 3D array with shapes (n_examples, seq_len, n_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldUup-_Qyyh2"
      },
      "source": [
        "What will be `n_features` in our case ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90SP7KoTyyh3"
      },
      "source": [
        "`n_features` est la dimension de chaque vecteur de caractères. Dans notre cas, il s'agit du nombre de caractères uniques dans le dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwkwafxdyyh4"
      },
      "source": [
        "Code a function **build_X_and_y(string, i_char, seq_lenght)** which takes a string, a **seq_length** number and a position.\n",
        "\n",
        "\n",
        "It should create X by by getting all character between i and i + seq_length\n",
        "and create y by getting the character following the X sequence\n",
        "it returns X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ToDrNcT8yyh5"
      },
      "outputs": [],
      "source": [
        "def build_X_and_y(\n",
        "    string: str,\n",
        "    i_char: int,\n",
        "    seq_length: int,\n",
        "    mol_encoder: MolEncoder = None,\n",
        "    one_hot: bool = False,\n",
        "):\n",
        "    encode_method = (\n",
        "        mol_encoder.get_int\n",
        "        if not one_hot\n",
        "        else lambda x: mol_encoder.get_one_hot(char=x)\n",
        "    )\n",
        "    X = [encode_method(char) for char in string[i_char : i_char + seq_length]]\n",
        "    y = encode_method(string[i_char + seq_length])\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfRJ_Lpkyyh4"
      },
      "source": [
        "Test your function on the following string \"OCC(C)(C)c1ccc\" with seq_length = 4 and i = [1, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "l'encodage de C(C est [17, 2, 17] et le caractère suivant est 3\n",
            "l'encodage de (C) est [2, 17, 3] et le caractère suivant est 2\n",
            "l'encodage de C)( est [17, 3, 2] et le caractère suivant est 17\n"
          ]
        }
      ],
      "source": [
        "tested_string = \"CC(C)(C)c1ccc\"\n",
        "seq_len = 3\n",
        "for i_char in range(1, 4):\n",
        "    X, y = build_X_and_y(\n",
        "        tested_string, i_char=i_char, seq_length=seq_len, mol_encoder=mol_encoder\n",
        "    )\n",
        "    print(\n",
        "        f\"l'encodage de {tested_string[i_char:i_char+seq_len]} est {X} et le caractère suivant est {y}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9DdyLSUyyh5"
      },
      "source": [
        "By using build_X_and_y and map_char_to_int build a list nameed X_train and a list named y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "xRb61XzXyyh6"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = [], []\n",
        "for mol in df[\"smiles\"]:\n",
        "    for i in range(len(mol) - seq_len):\n",
        "        X, y = build_X_and_y(mol, i_char=i, seq_length=seq_len, mol_encoder=mol_encoder)\n",
        "        X_train.append(X)\n",
        "        y_train.append(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fubbPe7Vyyh6"
      },
      "source": [
        "Create numpy arrays from the lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "il1hbrsbyyh7"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((42242, 3), (42242,))"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb5Y3ERkyyh8"
      },
      "source": [
        "Reshape the X numpy array (n_examples, seq_lenght, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "T6mf5a4Dyyh8"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((42242, 3, 1), (42242,))"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7x4U0tCyyh9"
      },
      "source": [
        "Normalize X by dividing each values by the total number of unic characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "lHTjPnv4yyh9"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / mol_encoder.voc_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert np.all(X_train < 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWnIpi2uyyh9"
      },
      "source": [
        "Import Keras and build (at least) a two layered LSTM network with 128 neurone in each.\n",
        "\n",
        "You can also add Dropoutlayers\n",
        "\n",
        "Do you think you should use the return_sequences = True ? If yes, when ?\n",
        "\n",
        "\n",
        "Add a Dense layer on top with with the appropriate activation function and number of neurones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42242, 3, 1)"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "9a0Vz4L8yyiM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-23 19:11:49.321577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-09-23 19:11:49.324846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-09-23 19:11:49.326819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1cAV53EyyiN"
      },
      "source": [
        "Compile the model with the appropriate loss function and the adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "6q2XpZQ4yyiO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_52 (LSTM)              (None, 128)               66560     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,689\n",
            "Trainable params: 66,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIq8gdLyyyiP"
      },
      "source": [
        "Train the model on 20 epochs and 10 examples (yeah you read correctly) and check that the model overfits !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert X_train to tensor\n",
        "n_samples = 10\n",
        "X_train_tensor = tf.convert_to_tensor(X_train[:n_samples])\n",
        "y_train_tensor = tf.convert_to_tensor(y_train[:n_samples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-23 19:04:31.335041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-09-23 19:04:31.338379: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-09-23 19:04:31.342381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-09-23 19:04:32.121285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-09-23 19:04:32.123738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-09-23 19:04:32.125569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc214b0c8e0>"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_tensor, y_train_tensor, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "altB1J4xyyiQ"
      },
      "source": [
        "If it does not overfit try to fix data prep and model architecture so it does"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SUJYSK7yyiQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMCFxz-wyyiR"
      },
      "source": [
        "Create a function **make_prediction(seed_start)** which takes a starting string sequence and uses it to generate a molecule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulAAk9plyyiS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHb0mnp5yyiS"
      },
      "source": [
        "generate a molecule of your overfitted model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWlnEs0-yyiT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyZcbVC4yyiU"
      },
      "source": [
        "Make a model checkpoint so that the model is saved after each epoch\n",
        "if you train on a plateform and it stops you do not lose your training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhOqrs9NyyiV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEa4hmZyyiV"
      },
      "source": [
        "Now go to your favorite plateform (colab or something else) and train the dataset on the whole data for 10 epochs and batch size 256\n",
        "\n",
        "it should take a long time so either follow the class or go take a nap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iyk8BvZyyiW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGzxqv3hyyiX"
      },
      "source": [
        "Generate between 100 and 1000 molecules.\n",
        "\n",
        "create a list where molecules have between 10 and 50 atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E9fhvHQyyiY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwmMBBnyyiY"
      },
      "source": [
        "With rdkit compute the Quantified Estimated Drug likelyness (QED) of each molecule in this subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPboRawUyyiZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9En9mvfOyyiZ"
      },
      "source": [
        "Bonus 1 : Using rdkit, compute the quantitative estimation of drug-likeness (QED) of your generated molecules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEVMckghyyia"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtCbYnIuyyib"
      },
      "source": [
        "Bonus 2 : try to adapt a transformer model training from hugging face to see if it is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnMy9_I1yyib"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
