{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/basth94/ml-bio-molecule-practical-work-2?scriptVersionId=144214271\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# RNN Based molucule generation\n\nLaurent Cetinsoy\n\nIn this hands-on we want to generate molecule formulas for denovo-drug discovery.\n\nFor that we need to use Generative models. Generative models are models which goes beyond classification or simple regression : they are able to generate data that look like previously seens dataset.\n\nThere exists a lot of models :\n\n- Bayesian models like graphical models\n- Recurrent models (for sequence generation like texte)\n- Variational auto encoders\n- Generative adversarial models\n- Flow and diffusion models\n\n\nIn the hands-on we will start by  trainning a character based RNN to generate smile molecules\n\n\nWe want to feed smile representations of molecules to an RNN.\nThe basic idea is we will train it to predict the next smile token of a molecule given the previous one.\n\nFor instance for the following molecule \"CC(=O)NC1=CC=C(O)C=C1\" will may give to the model\n\nX = \"CC(=O)N\"\ny = C\n\nand ask the RNN to learn to predict y given X\n\nLike a standard language model !\n","metadata":{"id":"7YhDx0Tsyyhd"}},{"cell_type":"markdown","source":"## RNN Language model\n\n\nA language model is a model which predict the next token of a sequence given the previous ones :\n\n$ P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n\n\nThis model can be learned with a Recurrent neural network\n\n$ y = P(X_t | X_{t-1}, X_{t-2}, ..., X_{t-p}) = RNN_{\\theta} (X_{t-1}, X_{t-2}, ..., X_{t-p})  $\n\n\nIn order to train such model you need a corpus of data.\n\n\n\nThere are two main ways to do that : Word level model or character level model\n\nFor character level models, an interesting resource is : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n\n","metadata":{"id":"c-Que9IFyyhk"}},{"cell_type":"markdown","source":"Explain briefly what is the difference between word based language model and character based language model","metadata":{"id":"ZaSGBHWXyyhm"}},{"cell_type":"markdown","source":"Les modèles basés sur des caractères fonctionnent sur la prédiction de la lettre la plus probable de suivre une séquence. Les modèles basés sur des mots fonctionnent en revanche sur la prédiction du mot le plus probable.","metadata":{"id":"7c3FB6X4yyhn"}},{"cell_type":"markdown","source":"## Import and dependancies","metadata":{}},{"cell_type":"code","source":"!pip install rdkit-pypi","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:22.563606Z","iopub.execute_input":"2023-09-25T16:18:22.56399Z","iopub.status.idle":"2023-09-25T16:18:39.185617Z","shell.execute_reply.started":"2023-09-25T16:18:22.563956Z","shell.execute_reply":"2023-09-25T16:18:39.184416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yaml\nimport pandas as pd\nimport numpy as np\nimport random\nfrom rdkit.Chem import QED,MolFromSmiles\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional,Input\nfrom rdkit.Chem import MolToSmiles\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom rdkit.Chem.Draw import MolToImage","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:35:16.428408Z","iopub.execute_input":"2023-09-25T16:35:16.428812Z","iopub.status.idle":"2023-09-25T16:35:16.437493Z","shell.execute_reply.started":"2023-09-25T16:35:16.42878Z","shell.execute_reply":"2023-09-25T16:35:16.43607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving config\nIn order to keep best config for our RNN, we will keep its config in `config.yml` file","metadata":{}},{"cell_type":"code","source":"def save_config(dictionnaire, chemin_fichier=\"config.yml\"):\n    with open(chemin_fichier, \"w\") as fichier:\n        yaml.dump(dictionnaire, fichier)\n    print(\"Fichier YAML sauvegardé avec succès.\")\n\n\ndef read_yaml(chemin_fichier):\n    if os.path.exists(chemin_fichier):\n        with open(chemin_fichier, \"r\") as fichier:\n            contenu = yaml.safe_load(fichier)\n    else:\n        contenu = {}\n    return contenu","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:53.956707Z","iopub.execute_input":"2023-09-25T16:18:53.957409Z","iopub.status.idle":"2023-09-25T16:18:53.965697Z","shell.execute_reply.started":"2023-09-25T16:18:53.957373Z","shell.execute_reply":"2023-09-25T16:18:53.963175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {}","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:53.968926Z","iopub.execute_input":"2023-09-25T16:18:53.969349Z","iopub.status.idle":"2023-09-25T16:18:53.974767Z","shell.execute_reply.started":"2023-09-25T16:18:53.969314Z","shell.execute_reply":"2023-09-25T16:18:53.97363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{"id":"WU_SbWlJyyhn"}},{"cell_type":"markdown","source":"Dowload the following dataset : https://github.com/joeymach/Leveraging-VAE-to-generate-molecules","metadata":{"id":"9CAnQcj3yyho"}},{"cell_type":"code","source":"! [ -e 250k_smiles.csv ] || wget https://raw.githubusercontent.com/joeymach/Leveraging-VAE-to-generate-molecules/master/250k_smiles.csv","metadata":{"id":"0n4Vt5n4o8jc","outputId":"a7b05970-ab63-4a8a-9faa-c8d50ee54d5d","execution":{"iopub.status.busy":"2023-09-25T16:18:53.976385Z","iopub.execute_input":"2023-09-25T16:18:53.976881Z","iopub.status.idle":"2023-09-25T16:18:55.341348Z","shell.execute_reply.started":"2023-09-25T16:18:53.976824Z","shell.execute_reply":"2023-09-25T16:18:55.340131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import pandas and load the first 1000 lines","metadata":{"id":"nyvW9PMyyyhr"}},{"cell_type":"code","source":"df = pd.read_csv(filepath_or_buffer=\"250k_smiles.csv\", nrows=1000)","metadata":{"id":"jdBAbT-Apc4g","execution":{"iopub.status.busy":"2023-09-25T16:18:55.344343Z","iopub.execute_input":"2023-09-25T16:18:55.345064Z","iopub.status.idle":"2023-09-25T16:18:55.371714Z","shell.execute_reply.started":"2023-09-25T16:18:55.345022Z","shell.execute_reply":"2023-09-25T16:18:55.370742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the first rows of the dataframe","metadata":{"id":"gO3XWPQMyyhs"}},{"cell_type":"code","source":"df.head()","metadata":{"id":"zjQ6_NK3yyht","outputId":"fb967260-a44c-48ce-de64-1886c2c71665","execution":{"iopub.status.busy":"2023-09-25T16:18:55.373136Z","iopub.execute_input":"2023-09-25T16:18:55.373559Z","iopub.status.idle":"2023-09-25T16:18:55.408251Z","shell.execute_reply.started":"2023-09-25T16:18:55.373526Z","shell.execute_reply":"2023-09-25T16:18:55.40729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processing the data\n\nWe need to do the following things :\n\n- convert smile tokens to numbers\n- build  smile token sequences and corresponding labels pairs","metadata":{"id":"VfyMV4QXyyhu"}},{"cell_type":"markdown","source":"Compute the biggest smile molecule size","metadata":{"id":"C-wwZXCOyyhu"}},{"cell_type":"code","source":"len(max(df[\"smiles\"], key=lambda s: len(s)))","metadata":{"id":"sjihMHOYuYz0","outputId":"778e12b6-4606-4140-8c1d-dc1f51a01e44","execution":{"iopub.status.busy":"2023-09-25T16:18:55.410677Z","iopub.execute_input":"2023-09-25T16:18:55.411819Z","iopub.status.idle":"2023-09-25T16:18:55.41982Z","shell.execute_reply.started":"2023-09-25T16:18:55.411781Z","shell.execute_reply":"2023-09-25T16:18:55.418785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code a function unic_characters(string) which return the unic characters in a string","metadata":{"id":"Ocxq6YQmuvMw"}},{"cell_type":"code","source":"def unic_characters(string :str):\n    \"\"\"\n    \"\"\"\n    return np.unique(list(string))","metadata":{"id":"PuGJsUIVA3il","execution":{"iopub.status.busy":"2023-09-25T16:18:55.421419Z","iopub.execute_input":"2023-09-25T16:18:55.422258Z","iopub.status.idle":"2023-09-25T16:18:55.430092Z","shell.execute_reply.started":"2023-09-25T16:18:55.422223Z","shell.execute_reply":"2023-09-25T16:18:55.428926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testons cette fonction:","metadata":{}},{"cell_type":"code","source":"unic_characters(\"AAAABAAACCCDDDEE\")","metadata":{"id":"kfQN1kx-8qz5","outputId":"0bbc3566-c781-4c8c-ea1e-3b327df16043","execution":{"iopub.status.busy":"2023-09-25T16:18:55.435635Z","iopub.execute_input":"2023-09-25T16:18:55.43669Z","iopub.status.idle":"2023-09-25T16:18:55.44497Z","shell.execute_reply.started":"2023-09-25T16:18:55.436656Z","shell.execute_reply":"2023-09-25T16:18:55.44364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Concatenate all smile string of the pandas dataframe and use **unic_characters** to get the unic_characters","metadata":{"id":"4DITuFSeyyhx"}},{"cell_type":"code","source":"unic_chars = unic_characters(df[\"smiles\"].sum())","metadata":{"id":"Pweel8bxyyhx","execution":{"iopub.status.busy":"2023-09-25T16:18:55.446562Z","iopub.execute_input":"2023-09-25T16:18:55.447817Z","iopub.status.idle":"2023-09-25T16:18:55.473836Z","shell.execute_reply.started":"2023-09-25T16:18:55.447779Z","shell.execute_reply":"2023-09-25T16:18:55.472975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code a function **map_char_to_int(unic_chars)** which returns a dictionnary where each char is assigned an int value.\nAdd a character to specify the end of the molecule (like \"\\n\")\n","metadata":{"id":"LXmrYw-nyyhy"}},{"cell_type":"code","source":"def map_char_to_int(unic_chars):\n    dictionnary = {}\n    for i, char in enumerate(unic_chars):\n        dictionnary[char] = i\n    return dictionnary","metadata":{"id":"dPvQzt1Oyyhy","execution":{"iopub.status.busy":"2023-09-25T16:18:55.475056Z","iopub.execute_input":"2023-09-25T16:18:55.475941Z","iopub.status.idle":"2023-09-25T16:18:55.480638Z","shell.execute_reply.started":"2023-09-25T16:18:55.475911Z","shell.execute_reply":"2023-09-25T16:18:55.479761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_char_to_int(unic_chars)","metadata":{"id":"lJAKz2_KCN12","outputId":"4fee2695-3923-4df0-9b57-6d1a60524ced","execution":{"iopub.status.busy":"2023-09-25T16:18:55.481912Z","iopub.execute_input":"2023-09-25T16:18:55.482614Z","iopub.status.idle":"2023-09-25T16:18:55.495215Z","shell.execute_reply.started":"2023-09-25T16:18:55.482582Z","shell.execute_reply":"2023-09-25T16:18:55.494113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code a function map_int_to_char(unic_chars) which returns the reverse mapping.\n\nIf you want you can merge both functions in a class","metadata":{"id":"GbrgQmRgyyhz"}},{"cell_type":"code","source":"def map_int_to_char(unic_chars):\n    dictionnary = {}\n    for i, char in enumerate(unic_chars):\n        dictionnary[i] = char\n    return dictionnary","metadata":{"id":"mX3883sYyyh0","execution":{"iopub.status.busy":"2023-09-25T16:18:55.496565Z","iopub.execute_input":"2023-09-25T16:18:55.497631Z","iopub.status.idle":"2023-09-25T16:18:55.506539Z","shell.execute_reply.started":"2023-09-25T16:18:55.497596Z","shell.execute_reply":"2023-09-25T16:18:55.505444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Implémentons la classe MolEncoder, qui va générer ses propres dictionnaires de mapping en fonction des `unic_caracters` ou d'un ensemble de données `string_set` (pour les Dataframes ayant une taille importante).","metadata":{}},{"cell_type":"code","source":"class MolEncoder:\n    def __init__(self, unic_characters: np.array = None, string_set =None):\n        if unic_characters is not None:\n            self.unic_chars = unic_characters\n            self.char_to_int = map_char_to_int(unic_chars)\n            self.int_to_char = map_int_to_char(unic_chars)\n            self.voc_len = len(unic_chars)\n            return\n        int_val = 0 \n        self.char_to_int = {}\n        self.int_to_char = {}\n        for chaine in tqdm(string_set):\n            for char in chaine:\n                if char not in self.char_to_int.keys():\n                    self.char_to_int[char] = int_val\n                    self.int_to_char[int_val] = char\n                    int_val += 1\n        self.unic_chars = [key for key in self.char_to_int.keys()]\n        self.voc_len = len(self.unic_chars)\n    \n    def get_char(self, int_val):\n        return self.int_to_char[int_val]\n\n    def get_int(self, char):\n        return self.char_to_int[char]\n\n    def encode_mol(self, smiles):\n        return np.array([self.char_to_int[char] for char in smiles])\n\n    def get_one_hot(self, int_value: int = None, char: chr = None):\n        if int_value is None:\n            int_value = self.get_int(char)\n        elif char is None:\n            char = self.get_char(int_value)\n        one_hot = np.zeros(self.voc_len)\n        one_hot[int_value] = 1\n        return one_hot\n\n    def decode_mol(self, encoded_mol):\n        return \"\".join([self.int_to_char[int] for int in encoded_mol])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:55.50802Z","iopub.execute_input":"2023-09-25T16:18:55.50879Z","iopub.status.idle":"2023-09-25T16:18:55.521739Z","shell.execute_reply.started":"2023-09-25T16:18:55.508758Z","shell.execute_reply":"2023-09-25T16:18:55.521089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unic_chars = unic_characters(df[\"smiles\"].sum())\nmol_encoder = MolEncoder(unic_chars)\nprint(mol_encoder.get_char(17))\nprint(mol_encoder.get_int(\"C\"))\nprint(mol_encoder.get_one_hot(17))\nassert np.all(mol_encoder.get_one_hot(17) == mol_encoder.get_one_hot(char=\"C\"))","metadata":{"id":"6PyYopQ3F_H9","outputId":"f9ba15f7-4c3b-4c9c-b781-ffd1bec8a670","execution":{"iopub.status.busy":"2023-09-25T16:40:10.483529Z","iopub.execute_input":"2023-09-25T16:40:10.48393Z","iopub.status.idle":"2023-09-25T16:40:10.51489Z","shell.execute_reply.started":"2023-09-25T16:40:10.483889Z","shell.execute_reply":"2023-09-25T16:40:10.51362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mol_smile = df[\"smiles\"][random.randint(0, len(df))]\necnoded = mol_encoder.encode_mol(mol_smile)\nassert mol_encoder.decode_mol(ecnoded) == mol_smile","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:11.847781Z","iopub.execute_input":"2023-09-25T16:40:11.849158Z","iopub.status.idle":"2023-09-25T16:40:11.855231Z","shell.execute_reply.started":"2023-09-25T16:40:11.849112Z","shell.execute_reply":"2023-09-25T16:40:11.854244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For each smile molecule add the ending token to it","metadata":{"id":"1etZs7T3yyh1"}},{"cell_type":"markdown","source":"L'algorithme implémenté encode déjà l'ending token.","metadata":{}},{"cell_type":"markdown","source":"## Building the dataset\n\nNow we will create the dataset so that it has the good share for our Keras LSTM model\n\nRemember Keras recurrent models expect a 3D array with shapes (n_examples, seq_len, n_features)\n\n","metadata":{"id":"QpuIn5z1yyh2"}},{"cell_type":"markdown","source":"What will be `n_features` in our case ?","metadata":{"id":"ldUup-_Qyyh2"}},{"cell_type":"markdown","source":"`n_features` est la dimension de chaque vecteur de caractères. Dans notre cas c'est 1, puisque chaque caractère est représenté par un entier. Pour les cas des vecteurs en one-hot encoding `n_features` sera égal à la taille du vocabulaire.","metadata":{"id":"90SP7KoTyyh3"}},{"cell_type":"markdown","source":"Code a function **build_X_and_y(string, i_char, seq_lenght)** which takes a string, a **seq_length** number and a position.\n\n\nIt should create X by by getting all character between i and i + seq_length\nand create y by getting the character following the X sequence\nit returns X and y","metadata":{"id":"Jwkwafxdyyh4"}},{"cell_type":"code","source":"def build_X_and_y(\n    string: str,\n    i_char: int,\n    seq_length: int,\n    mol_encoder: MolEncoder = None,\n    one_hot: bool = False,\n):\n    encode_method = (\n        mol_encoder.get_int\n        if not one_hot\n        else lambda x: mol_encoder.get_one_hot(char=x)\n    )\n    X = [encode_method(char) for char in string[i_char : i_char + seq_length]]\n    y = encode_method(string[i_char + seq_length])\n    return X, y","metadata":{"id":"ToDrNcT8yyh5","execution":{"iopub.status.busy":"2023-09-25T16:40:15.263691Z","iopub.execute_input":"2023-09-25T16:40:15.264085Z","iopub.status.idle":"2023-09-25T16:40:15.27048Z","shell.execute_reply.started":"2023-09-25T16:40:15.264046Z","shell.execute_reply":"2023-09-25T16:40:15.269532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test your function on the following string \"OCC(C)(C)c1ccc\" with seq_length = 4 and i = [1, 2, 3]","metadata":{"id":"PfRJ_Lpkyyh4"}},{"cell_type":"code","source":"tested_string = \"CC(C)(C)c1ccc\"\nseq_len = 3\nfor i_char in range(1, 4):\n    X, y = build_X_and_y(\n        tested_string, i_char=i_char, seq_length=seq_len, mol_encoder=mol_encoder\n    )\n    print(\n        f\"l'encodage de {tested_string[i_char:i_char+seq_len]} est {X} et le caractère suivant est {y}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:17.073922Z","iopub.execute_input":"2023-09-25T16:40:17.074639Z","iopub.status.idle":"2023-09-25T16:40:17.081317Z","shell.execute_reply.started":"2023-09-25T16:40:17.074599Z","shell.execute_reply":"2023-09-25T16:40:17.080158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By using build_X_and_y and map_char_to_int build a list nameed X_train and a list named y_train","metadata":{"id":"y9DdyLSUyyh5"}},{"cell_type":"code","source":"def generate_ds(seq_len = 10, mol_encoder = None):\n    X_train, y_train = [], []\n    for mol in df[\"smiles\"]:\n        for i in range(len(mol) - seq_len):\n            X, y = build_X_and_y(mol, i_char=i, seq_length=seq_len, mol_encoder=mol_encoder)\n            X_train.append(X)\n            y_train.append(y)\n    return np.array(X_train),np.array(y_train)","metadata":{"id":"xRb61XzXyyh6","execution":{"iopub.status.busy":"2023-09-25T16:40:19.197394Z","iopub.execute_input":"2023-09-25T16:40:19.198163Z","iopub.status.idle":"2023-09-25T16:40:19.204941Z","shell.execute_reply.started":"2023-09-25T16:40:19.19811Z","shell.execute_reply":"2023-09-25T16:40:19.203784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create numpy arrays from the lists","metadata":{"id":"fubbPe7Vyyh6"}},{"cell_type":"code","source":"X_train ,y_train = generate_ds(10,mol_encoder)","metadata":{"id":"il1hbrsbyyh7","execution":{"iopub.status.busy":"2023-09-25T16:18:55.613231Z","iopub.execute_input":"2023-09-25T16:18:55.613974Z","iopub.status.idle":"2023-09-25T16:18:55.858286Z","shell.execute_reply.started":"2023-09-25T16:18:55.61394Z","shell.execute_reply":"2023-09-25T16:18:55.857272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:55.861781Z","iopub.execute_input":"2023-09-25T16:18:55.862138Z","iopub.status.idle":"2023-09-25T16:18:55.869015Z","shell.execute_reply.started":"2023-09-25T16:18:55.862111Z","shell.execute_reply":"2023-09-25T16:18:55.868119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reshape the X numpy array (n_examples, seq_lenght, 1)","metadata":{"id":"Wb5Y3ERkyyh8"}},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)","metadata":{"id":"T6mf5a4Dyyh8","execution":{"iopub.status.busy":"2023-09-25T16:18:55.870516Z","iopub.execute_input":"2023-09-25T16:18:55.871146Z","iopub.status.idle":"2023-09-25T16:18:55.880325Z","shell.execute_reply.started":"2023-09-25T16:18:55.871104Z","shell.execute_reply":"2023-09-25T16:18:55.879296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:55.882027Z","iopub.execute_input":"2023-09-25T16:18:55.882482Z","iopub.status.idle":"2023-09-25T16:18:55.893143Z","shell.execute_reply.started":"2023-09-25T16:18:55.882446Z","shell.execute_reply":"2023-09-25T16:18:55.89192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalize X by dividing each values by the total number of unic characters","metadata":{"id":"l7x4U0tCyyh9"}},{"cell_type":"code","source":"X_train = X_train / mol_encoder.voc_len","metadata":{"id":"lHTjPnv4yyh9","execution":{"iopub.status.busy":"2023-09-25T16:18:55.894731Z","iopub.execute_input":"2023-09-25T16:18:55.895231Z","iopub.status.idle":"2023-09-25T16:18:55.906587Z","shell.execute_reply.started":"2023-09-25T16:18:55.895182Z","shell.execute_reply":"2023-09-25T16:18:55.905441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert np.all(X_train < 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:18:55.90874Z","iopub.execute_input":"2023-09-25T16:18:55.910114Z","iopub.status.idle":"2023-09-25T16:18:55.915676Z","shell.execute_reply.started":"2023-09-25T16:18:55.910076Z","shell.execute_reply":"2023-09-25T16:18:55.914636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Keras and build (at least) a two layered LSTM network with 128 neurone in each.\n\nYou can also add Dropoutlayers\n\nDo you think you should use the return_sequences = True ? If yes, when ?\n\n\nAdd a Dense layer on top with with the appropriate activation function and number of neurones\n","metadata":{"id":"iWnIpi2uyyh9"}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=1, activation=\"sigmoid\"))","metadata":{"id":"9a0Vz4L8yyiM","execution":{"iopub.status.busy":"2023-09-25T16:18:55.917024Z","iopub.execute_input":"2023-09-25T16:18:55.91815Z","iopub.status.idle":"2023-09-25T16:19:02.882834Z","shell.execute_reply.started":"2023-09-25T16:18:55.918116Z","shell.execute_reply":"2023-09-25T16:19:02.881885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compile the model with the appropriate loss function and the adam optimizer","metadata":{"id":"q1cAV53EyyiN"}},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.summary()","metadata":{"id":"6q2XpZQ4yyiO","execution":{"iopub.status.busy":"2023-09-25T16:19:02.888999Z","iopub.execute_input":"2023-09-25T16:19:02.889312Z","iopub.status.idle":"2023-09-25T16:19:02.929287Z","shell.execute_reply.started":"2023-09-25T16:19:02.889287Z","shell.execute_reply":"2023-09-25T16:19:02.928512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model on 20 epochs and 10 examples (yeah you read correctly) and check that the model overfits !","metadata":{"id":"ZIq8gdLyyyiP"}},{"cell_type":"code","source":"# Convert X_train to tensor\nn_samples = 10\nX_train_tensor = tf.convert_to_tensor(X_train[:n_samples])\ny_train_tensor = tf.convert_to_tensor(y_train[:n_samples])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:19:02.930398Z","iopub.execute_input":"2023-09-25T16:19:02.930769Z","iopub.status.idle":"2023-09-25T16:19:02.940947Z","shell.execute_reply.started":"2023-09-25T16:19:02.930735Z","shell.execute_reply":"2023-09-25T16:19:02.939802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nconfig['epochs'] = n_epochs \nhistory = model.fit(X_train_tensor, y_train_tensor, epochs=n_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:19:02.942502Z","iopub.execute_input":"2023-09-25T16:19:02.942933Z","iopub.status.idle":"2023-09-25T16:19:16.581057Z","shell.execute_reply.started":"2023-09-25T16:19:02.942895Z","shell.execute_reply":"2023-09-25T16:19:16.579901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If it does not overfit try to fix data prep and model architecture so it does","metadata":{"id":"altB1J4xyyiQ"}},{"cell_type":"markdown","source":"Pour la préparation de la donnée nous allons appliquer du one hot encoding sur les caractères. Ainsi, nous aurons une matrice de dimension (`n_examples`, `seq_length`, `n_features`) avec `n_features` = nombre de caractères uniques. Nous allons ensuite normaliser cette matrice en divisant chaque valeur par le nombre de caractères uniques. Enfin, nous allons utiliser la fonction return_sequences = True pour que le modèle renvoie une séquence de sortie pour chaque entrée. Cela nous permettra de prédire le caractère suivant pour chaque caractère de la séquence d'entrée.","metadata":{}},{"cell_type":"code","source":"seq_len = 20\nconfig[\"seq_len\"] = seq_len\ndef generate_one_hot_ds(seq_len,mol_encoder,smiles_set):\n    X_train, y_train = [],[]\n    for mol in tqdm(smiles_set):\n        for i in range(len(mol) - seq_len):\n            X, y = build_X_and_y(\n                mol, i_char=i, seq_length=seq_len, mol_encoder=mol_encoder, one_hot=True\n            )\n            X_train.append(X)\n            y_train.append(y)\n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n    assert X_train.shape[1:] == (seq_len, mol_encoder.voc_len)\n    assert y_train.shape[1] == (mol_encoder.voc_len)\n    return X_train,y_train\n","metadata":{"id":"6SUJYSK7yyiQ","execution":{"iopub.status.busy":"2023-09-25T16:40:30.435569Z","iopub.execute_input":"2023-09-25T16:40:30.435997Z","iopub.status.idle":"2023-09-25T16:40:30.444029Z","shell.execute_reply.started":"2023-09-25T16:40:30.435961Z","shell.execute_reply":"2023-09-25T16:40:30.442891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_one_hot_model(seq_len, voc_len):\n    model = Sequential(\n        [\n            Input(shape=(seq_len, voc_len)),\n            LSTM(128,return_sequences=True),\n            Dropout(0.2),\n            LSTM(128),\n            Dropout(0.2),\n            Dense(voc_len, activation=\"softmax\"),\n        ]\n    )\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3) # tf.keras.optimizers.RMSprop(learning_rate=0.01)\n    model.compile(\n        loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n    )\n    config[\"model_config\"] = model.get_config()\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:32.566208Z","iopub.execute_input":"2023-09-25T16:40:32.566991Z","iopub.status.idle":"2023-09-25T16:40:32.575759Z","shell.execute_reply.started":"2023-09-25T16:40:32.566952Z","shell.execute_reply":"2023-09-25T16:40:32.573289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Générons maintenant les datasets pour entrainer notre nouveau modèle.","metadata":{}},{"cell_type":"code","source":"X_train, y_train = generate_one_hot_ds(seq_len,mol_encoder,df['smiles'])\nX_train_tensor = tf.convert_to_tensor(X_train)\ny_train_tensor = tf.convert_to_tensor(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:36.04347Z","iopub.execute_input":"2023-09-25T16:40:36.044361Z","iopub.status.idle":"2023-09-25T16:40:38.190183Z","shell.execute_reply.started":"2023-09-25T16:40:36.044318Z","shell.execute_reply":"2023-09-25T16:40:38.18912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construisons maintenant ce modèle.","metadata":{}},{"cell_type":"code","source":"model = build_one_hot_model(seq_len,mol_encoder.voc_len)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:42.270645Z","iopub.execute_input":"2023-09-25T16:40:42.27107Z","iopub.status.idle":"2023-09-25T16:40:42.861483Z","shell.execute_reply.started":"2023-09-25T16:40:42.271035Z","shell.execute_reply":"2023-09-25T16:40:42.860687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Afin de pouvoir faire des plots d'évolution de l'entrainement nous allons sauvegarder l'historique du fitting du modèle.","metadata":{}},{"cell_type":"code","source":"def save_history(model, history,hist_file_name):\n    history_df = pd.DataFrame(history.history)\n    hist_file_name = f\"{model.name}_history.csv\"\n    history_df.to_csv(os.path.join(hist_file_name))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:19:18.884864Z","iopub.execute_input":"2023-09-25T16:19:18.885218Z","iopub.status.idle":"2023-09-25T16:19:18.894654Z","shell.execute_reply.started":"2023-09-25T16:19:18.885184Z","shell.execute_reply":"2023-09-25T16:19:18.89342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a function **make_prediction(seed_start)** which takes a starting string sequence and uses it to generate a molecule\n","metadata":{"id":"BMCFxz-wyyiR"}},{"cell_type":"code","source":"def make_prediction(seed_start: str,model,mol_encoder,seq_len):\n    seed = seed_start\n    for i in range(50):\n        X = np.zeros((1, seq_len, mol_encoder.voc_len))\n        for j, char in enumerate(seed[-seq_len:]):\n            X[0, j, mol_encoder.get_int(char)] = 1\n        y = model.predict(X,verbose=0)\n        next_char = mol_encoder.get_char(np.argmax(y))\n        seed += next_char\n        if next_char == \"\\n\":\n            break\n    return seed\n\ndef make_prediction_alternate(seed_start: str,model=None,mol_encoder=None,seq_len=0):\n    seed = \"\"\n    seed_start\n    for i in range(50):\n        X = np.zeros((1, seq_len, mol_encoder.voc_len))\n        for j, char in enumerate(seed_start):\n            X[0, j, mol_encoder.get_int(char)] = 1\n        y = model.predict(X,verbose=0)\n        next_char = mol_encoder.get_char(np.argmax(y))\n        seed_start = seed_start[1:] + next_char\n        seed += next_char\n        if next_char == \"\\n\":\n            break\n    return seed","metadata":{"id":"ulAAk9plyyiS","execution":{"iopub.status.busy":"2023-09-25T16:19:18.896383Z","iopub.execute_input":"2023-09-25T16:19:18.896725Z","iopub.status.idle":"2023-09-25T16:19:18.912161Z","shell.execute_reply.started":"2023-09-25T16:19:18.896694Z","shell.execute_reply":"2023-09-25T16:19:18.911194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lancons maintenant le modèle pour que celui-ci overfit.","metadata":{}},{"cell_type":"code","source":"def plot_history(history=None, file_name=None):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  \n\n    if file_name is None:\n        history_df = pd.DataFrame(history.history)\n    else:\n        history_df = pd.read_csv(file_name)\n\n    #\n    history_df[[\"val_accuracy\", \"accuracy\"]].plot(ax=ax1)\n    ax1.set_title('Précision')\n    ax1.set_xlabel('Époque')\n    ax1.set_ylabel('Précision')\n    ax1.legend([\"Validation\", \"Entraînement\"])\n\n    \n    history_df[[\"loss\", \"val_loss\"]].plot(ax=ax2)\n    ax2.set_title('Perte')\n    ax2.set_xlabel('Époque')\n    ax2.set_ylabel('Perte')\n    ax2.legend([\"Entraînement\", \"Validation\"])\n\n    plt.suptitle(\"Historique d'entraînement\")  \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:41:43.094801Z","iopub.execute_input":"2023-09-25T17:41:43.095843Z","iopub.status.idle":"2023-09-25T17:41:43.105395Z","shell.execute_reply.started":"2023-09-25T17:41:43.095808Z","shell.execute_reply":"2023-09-25T17:41:43.104135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyCustomCallback(tf.keras.callbacks.Callback):\n    def __init__(self, patience:int=0, model_file:str=\"model.h5\"):\n        self.patience = patience\n        self.counter = 0\n        self.min_val_loss = float(\"inf\")\n        self.model_file_path = model_file\n        # self.model.save(os.path.join(self.model_file_path))\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_loss = logs.get(\"val_loss\")\n        \n        if val_loss < self.min_val_loss:\n            self.min_val_loss = val_loss\n            print(f\"\\nNew Mininimum for validation loss: {self.min_val_loss}\")\n            print(f\"Saving {self.model_file_path}, {epoch = }\")\n            self.model.save(os.path.join(self.model_file_path))","metadata":{"id":"hhOqrs9NyyiV","execution":{"iopub.status.busy":"2023-09-25T17:42:21.348804Z","iopub.execute_input":"2023-09-25T17:42:21.349844Z","iopub.status.idle":"2023-09-25T17:42:21.358271Z","shell.execute_reply.started":"2023-09-25T17:42:21.349807Z","shell.execute_reply":"2023-09-25T17:42:21.357061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config[\"callback_param\"] = dict(patience=2,model_file=\"one_hot_model_1.h5\")\ncallbacks = [MyCustomCallback(**config[\"callback_param\"])]\nmodel = build_one_hot_model(seq_len,mol_encoder.voc_len)\nhistory = model.fit(X_train_tensor, y_train_tensor, epochs=20,validation_split=0.2,callbacks=callbacks)\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:40:54.921623Z","iopub.execute_input":"2023-09-25T16:40:54.92271Z","iopub.status.idle":"2023-09-25T16:43:21.19493Z","shell.execute_reply.started":"2023-09-25T16:40:54.922663Z","shell.execute_reply":"2023-09-25T16:43:21.193874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"generate a molecule of your overfitted model","metadata":{"id":"cHb0mnp5yyiS"}},{"cell_type":"code","source":"seed_start = random.choice(df['smiles'])[:seq_len]\nmake_prediction(seed_start,model,mol_encoder,seq_len)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:43:34.905424Z","iopub.execute_input":"2023-09-25T16:43:34.906536Z","iopub.status.idle":"2023-09-25T16:43:35.350019Z","shell.execute_reply.started":"2023-09-25T16:43:34.906494Z","shell.execute_reply":"2023-09-25T16:43:35.348994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make a model checkpoint so that the model is saved after each epoch\nif you train on a plateform and it stops you do not lose your training","metadata":{"id":"AyZcbVC4yyiU"}},{"cell_type":"markdown","source":"Nous allons créer un callback adapté à notre situation en initiant une classe qui hérite de `tf.keras.callbacks.Callback`","metadata":{}},{"cell_type":"markdown","source":"Now go to your favorite plateform (colab or something else) and train the dataset on the whole data for 10 epochs and batch size 256\n\nit should take a long time so either follow the class or go take a nap","metadata":{"id":"chEa4hmZyyiV"}},{"cell_type":"markdown","source":"Commençons d'abord par charger les 10000 premières rangées du DataFrame.","metadata":{}},{"cell_type":"code","source":"full_df = pd.read_csv(filepath_or_buffer=\"250k_smiles.csv\",nrows=10000)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:44:14.997753Z","iopub.execute_input":"2023-09-25T16:44:14.998723Z","iopub.status.idle":"2023-09-25T16:44:15.023509Z","shell.execute_reply.started":"2023-09-25T16:44:14.998677Z","shell.execute_reply":"2023-09-25T16:44:15.02242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Générons ensuite le `MolEncoder`.","metadata":{}},{"cell_type":"code","source":"mol_encoder_2 = MolEncoder(string_set=full_df['smiles'])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:03:47.176715Z","iopub.execute_input":"2023-09-25T17:03:47.177756Z","iopub.status.idle":"2023-09-25T17:03:47.261952Z","shell.execute_reply.started":"2023-09-25T17:03:47.177706Z","shell.execute_reply":"2023-09-25T17:03:47.259589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous générons ensuite les datasets.","metadata":{}},{"cell_type":"code","source":"X_train, y_train = generate_one_hot_ds(seq_len,mol_encoder_2,full_df['smiles'])\nX_train_tensor = tf.convert_to_tensor(X_train)\ny_train_tensor = tf.convert_to_tensor(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:04:19.75052Z","iopub.execute_input":"2023-09-25T17:04:19.750959Z","iopub.status.idle":"2023-09-25T17:04:36.224729Z","shell.execute_reply.started":"2023-09-25T17:04:19.750924Z","shell.execute_reply":"2023-09-25T17:04:36.223463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous construisons ensuite le modèle approprié.","metadata":{}},{"cell_type":"code","source":"config[\"callback_param\"] = dict(patience=2,model_file=\"one_hot_model_2.h5\")\n\ncallbacks = [MyCustomCallback(**config[\"callback_param\"])]\nconfig[\"batch_size\"] = 256\nmodel = build_one_hot_model(seq_len,mol_encoder_2.voc_len)\nhistory = model.fit(X_train_tensor, y_train_tensor, epochs=20,validation_split=0.2,callbacks=callbacks,batch_size=config[\"batch_size\"])\nplot_history(history)","metadata":{"id":"-iyk8BvZyyiW","execution":{"iopub.status.busy":"2023-09-25T17:05:37.852965Z","iopub.execute_input":"2023-09-25T17:05:37.85338Z","iopub.status.idle":"2023-09-25T17:09:05.49184Z","shell.execute_reply.started":"2023-09-25T17:05:37.853348Z","shell.execute_reply":"2023-09-25T17:09:05.490788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate between 100 and 1000 molecules.","metadata":{"id":"QGzxqv3hyyiX"}},{"cell_type":"markdown","source":"Nous allons lancer la génréation de 500 molécules avec le modèle `one_hot_model_1.h5` lancé sur les 1000 premières molécules et le second `one_hot_model_2.h5` entrîné sur les 10000 premières. Ces molécules seront ensuite enregistrées.","metadata":{}},{"cell_type":"code","source":"def generate_molecules(n_molecules = 50,model = None,mol_encoder =None , seq_len = None,smiles_set = None):\n    \n    molecules_list = []\n    for i in tqdm(range(n_molecules)):\n        seed_start = random.choice(smiles_set)[:seq_len]\n        molecules_list.append(make_prediction(seed_start,model,mol_encoder,seq_len))\n\n    generated_df = pd.DataFrame({\"gen_mol\":molecules_list})\n    config[\"generated_molecules\"] = 'generated_molecules.csv'\n    generated_df.to_csv(config[\"generated_molecules\"])\n    return generated_df","metadata":{"id":"9E9fhvHQyyiY","execution":{"iopub.status.busy":"2023-09-25T17:00:32.924087Z","iopub.execute_input":"2023-09-25T17:00:32.924508Z","iopub.status.idle":"2023-09-25T17:00:32.932009Z","shell.execute_reply.started":"2023-09-25T17:00:32.924468Z","shell.execute_reply":"2023-09-25T17:00:32.930746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_molecules= 200\nseq_len = 20\nsmiles_set =full_df['smiles']\nmodel_1 = load_model('one_hot_model_1.h5')\ngen_df_1 = generate_molecules(n_molecules=n_molecules,model = model_1, mol_encoder= mol_encoder,seq_len = seq_len,smiles_set =smiles_set)\nmodel_2 = load_model('one_hot_model_2.h5')\ngen_df_2 = generate_molecules(n_molecules=n_molecules,model = model_2, mol_encoder= mol_encoder_2,seq_len = seq_len,smiles_set =smiles_set)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:23:51.095084Z","iopub.execute_input":"2023-09-25T17:23:51.095462Z","iopub.status.idle":"2023-09-25T17:25:38.382483Z","shell.execute_reply.started":"2023-09-25T17:23:51.09543Z","shell.execute_reply":"2023-09-25T17:25:38.380468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_df_1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:25:51.197634Z","iopub.execute_input":"2023-09-25T17:25:51.20019Z","iopub.status.idle":"2023-09-25T17:25:51.209766Z","shell.execute_reply.started":"2023-09-25T17:25:51.20014Z","shell.execute_reply":"2023-09-25T17:25:51.208722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_df_2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T17:25:53.724709Z","iopub.execute_input":"2023-09-25T17:25:53.725971Z","iopub.status.idle":"2023-09-25T17:25:53.737344Z","shell.execute_reply.started":"2023-09-25T17:25:53.725921Z","shell.execute_reply":"2023-09-25T17:25:53.736118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With rdkit compute the Quantified Estimated Drug likelyness (QED) of each molecule in this subset","metadata":{"id":"eQwmMBBnyyiY"}},{"cell_type":"markdown","source":"Implémentons maintenant une fonction qui génère des molécules selon les smiles générées par notre modèle.","metadata":{}},{"cell_type":"code","source":"from rdkit import rdBase\ndef get_valid_mols_list(gen_smiles):\n    rdBase.DisableLog('rdApp.error')\n    gen_mol_list = []\n    for gen_smiles in gen_smiles:\n        current_mol = MolFromSmiles(gen_smiles)\n        if current_mol is not None:\n            gen_mol_list.append(current_mol)\n        \n    rdBase.EnableLog('rdApp.error')\n    return gen_mol_list","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:06:34.851867Z","iopub.execute_input":"2023-09-25T18:06:34.852315Z","iopub.status.idle":"2023-09-25T18:06:34.858148Z","shell.execute_reply.started":"2023-09-25T18:06:34.852284Z","shell.execute_reply":"2023-09-25T18:06:34.857114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_mol_sets = []\nfiles_list = ['one_hot_model_1.h5','one_hot_model_2.h5']\nfor df,file_name in zip([gen_df_1,gen_df_2],files_list):\n    gen_mol_list = get_valid_mols_list(df[\"gen_mol\"])\n    gen_mol_sets.append(gen_mol_list)\n    n_gen_mol = len(gen_mol_list)\n    n_mol = len(df)\n    print(f'{n_gen_mol} molécules sur {n_mol} sont valides pour le modèle {file_name}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:19:55.97522Z","iopub.execute_input":"2023-09-25T18:19:55.975614Z","iopub.status.idle":"2023-09-25T18:19:55.996474Z","shell.execute_reply.started":"2023-09-25T18:19:55.975583Z","shell.execute_reply":"2023-09-25T18:19:55.995207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.set_facecolor('white')\nfor i,mol_set in enumerate(gen_mol_sets):\n    ax = fig.add_subplot(1,len(gen_mol_sets),i+1)\n    mol = random.choice(mol_set)\n    img = MolToImage(mol)\n    ax.set_title(f'Molécule générée \\n par {files_list[i]}')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:36:14.012946Z","iopub.execute_input":"2023-09-25T18:36:14.013372Z","iopub.status.idle":"2023-09-25T18:36:14.379725Z","shell.execute_reply.started":"2023-09-25T18:36:14.013341Z","shell.execute_reply":"2023-09-25T18:36:14.378714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create a list where molecules have between 10 and 50 atoms","metadata":{}},{"cell_type":"code","source":"between_10_and_50 = lambda mol: ((mol.GetNumAtoms() >= 10) and (mol.GetNumAtoms() <= 50))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:11:30.901787Z","iopub.execute_input":"2023-09-25T18:11:30.903149Z","iopub.status.idle":"2023-09-25T18:11:30.909242Z","shell.execute_reply.started":"2023-09-25T18:11:30.903104Z","shell.execute_reply":"2023-09-25T18:11:30.907948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qed_dfs = []\nfor mol_set,file_name in zip(gen_mol_sets,files_list):\n    gen_mol_list_10_50 = list(filter(between_10_and_50, mol_set ))\n    qed = lambda x : QED.qed(x)\n    qed_list = list(map(qed,gen_mol_list_10_50))\n    qed_df = pd.DataFrame({\n        f\"gen_mol_{file_name}\":list(map(MolToSmiles,gen_mol_list_10_50)),\n        \"qed\": qed_list\n    })\n    qed_dfs.append(qed_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:20:23.054099Z","iopub.execute_input":"2023-09-25T18:20:23.054578Z","iopub.status.idle":"2023-09-25T18:20:23.142456Z","shell.execute_reply.started":"2023-09-25T18:20:23.054543Z","shell.execute_reply":"2023-09-25T18:20:23.141433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nqed_dfs[0].head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:36:48.237831Z","iopub.execute_input":"2023-09-25T18:36:48.238275Z","iopub.status.idle":"2023-09-25T18:36:48.251234Z","shell.execute_reply.started":"2023-09-25T18:36:48.23824Z","shell.execute_reply":"2023-09-25T18:36:48.24993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qed_dfs[1].head()","metadata":{"execution":{"iopub.status.busy":"2023-09-25T18:36:41.801264Z","iopub.execute_input":"2023-09-25T18:36:41.802277Z","iopub.status.idle":"2023-09-25T18:36:41.820124Z","shell.execute_reply.started":"2023-09-25T18:36:41.802231Z","shell.execute_reply":"2023-09-25T18:36:41.819216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bonus 2 : try to adapt a transformer model training from hugging face to see if it is better","metadata":{"id":"PtCbYnIuyyib"}},{"cell_type":"markdown","source":"## Sauvegarde des configurations","metadata":{}},{"cell_type":"code","source":"save_config(config, \"config.yml\")","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:05:17.215098Z","iopub.execute_input":"2023-09-25T16:05:17.216252Z","iopub.status.idle":"2023-09-25T16:05:17.244699Z","shell.execute_reply.started":"2023-09-25T16:05:17.216216Z","shell.execute_reply":"2023-09-25T16:05:17.244117Z"},"trusted":true},"execution_count":null,"outputs":[]}]}